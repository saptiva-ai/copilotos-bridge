# Optimizaci√≥n de Recursos del Sistema

## üìä An√°lisis Actual de Recursos

### Estado de Memoria (RAM)

```
Total Sistema: 7.5 GB
Usado: 1.6 GB (21%)
Disponible: 5.6 GB (75%)
Swap: 2 GB (sin usar)
```

**Uso por Contenedor:**
| Contenedor | Memoria Usada | % del L√≠mite | L√≠mite |
|------------|---------------|--------------|--------|
| **API (FastAPI)** | 72 MB | 0.94% | 7.5 GB |
| **Web (Next.js)** | 372 MB | 4.87% | 7.5 GB |
| **MongoDB** | 180 MB | 2.37% | 7.5 GB |
| **Redis** | 4.3 MB | 0.06% | 7.5 GB |
| **TOTAL** | ~628 MB | ~8.4% | - |

### Estado de CPU

```
API:     0.23% - M√≠nimo (idle)
Web:     0.00% - Idle
MongoDB: 0.70% - Indexaci√≥n/Background tasks
Redis:   0.80% - Cache operations
```

### Estado de Disco

**Uso de Docker:**
```
Im√°genes:      59 GB total (55 GB reclaimable = 93%)
Contenedores:  18 MB
Vol√∫menes:     2.68 GB (2 GB reclaimable = 73%)
Build Cache:   21 GB (100% reclaimable)
```

**Problemas Identificados:**
- ‚úÖ Contenedores activos: Solo 628 MB (√≥ptimo)
- ‚ö†Ô∏è Im√°genes sin usar: 55 GB desperdiciados
- ‚ö†Ô∏è Vol√∫menes hu√©rfanos: 45 vol√∫menes no utilizados
- ‚ö†Ô∏è Build cache: 21 GB acumulado
- ‚ö†Ô∏è Im√°genes dangling: 7+ im√°genes de 380MB-1.33GB cada una

## üéØ Recomendaciones de Optimizaci√≥n

### 1. Limpieza Inmediata de Docker (Libera ~76 GB)

#### Limpieza Segura (Recomendada)
```bash
# 1. Eliminar im√°genes dangling (sin tag)
docker image prune -f
# Libera: ~5-8 GB

# 2. Eliminar build cache
docker builder prune -af
# Libera: ~21 GB

# 3. Eliminar vol√∫menes hu√©rfanos
docker volume prune -f
# Libera: ~2 GB

# 4. Eliminar contenedores detenidos
docker container prune -f
# Libera: ~100 MB

# TOTAL ESTIMADO: ~28-31 GB liberados
```

#### Limpieza Agresiva (Solo si necesitas m√°s espacio)
```bash
# Limpieza completa del sistema Docker
docker system prune -af --volumes

# ‚ö†Ô∏è ADVERTENCIA: Esto elimina:
# - Todos los contenedores detenidos
# - Todas las im√°genes no usadas por al menos un contenedor
# - Todos los vol√∫menes no usados
# - Todo el build cache
# TOTAL ESTIMADO: ~55+ GB liberados
```

#### Script de Limpieza Automatizada
```bash
#!/bin/bash
# scripts/docker-cleanup.sh

echo "üßπ Iniciando limpieza de Docker..."

# Im√°genes dangling
echo "1. Eliminando im√°genes sin tag..."
docker image prune -f

# Contenedores detenidos
echo "2. Eliminando contenedores detenidos..."
docker container prune -f

# Build cache (mantener √∫ltimos 7 d√≠as)
echo "3. Limpiando build cache antiguo..."
docker builder prune -af --filter "until=168h"

# Vol√∫menes hu√©rfanos (cuidado con datos)
echo "4. Eliminando vol√∫menes hu√©rfanos..."
docker volume prune -f

echo "‚úÖ Limpieza completada!"
docker system df
```

**Programar limpieza semanal:**
```bash
# Agregar a crontab
crontab -e

# Ejecutar cada domingo a las 3 AM
0 3 * * 0 /home/jazielflo/Proyects/copilotos-bridge/scripts/docker-cleanup.sh >> /tmp/docker-cleanup.log 2>&1
```

### 2. Optimizaci√≥n de Im√°genes Docker

#### A. Reducir Tama√±o de Imagen Web (De 1.33GB ‚Üí ~400MB)

**Problema Actual:**
- Imagen de desarrollo: 1.33 GB
- Incluye dependencias de dev innecesarias
- node_modules sin optimizar

**Soluci√≥n:**

```dockerfile
# apps/web/Dockerfile - Optimizaciones adicionales

# =========================================
# OPTIMIZACI√ìN 1: Usar alpine m√°s peque√±o
# =========================================
FROM node:20-alpine AS base
# Alpine es ~50 MB vs ~150 MB de slim

# =========================================
# OPTIMIZACI√ìN 2: Prune node_modules en prod
# =========================================
FROM base AS pruner

COPY --from=deps /app/node_modules ./node_modules
COPY --from=deps /app/packages ./packages
COPY apps/web ./apps/web

# Eliminar devDependencies
RUN pnpm prune --prod

# =========================================
# OPTIMIZACI√ìN 3: Usar en runner stage
# =========================================
FROM node:20-alpine AS runner
# ...
COPY --from=pruner --chown=app:appgroup /app/node_modules ./node_modules
# Resultado: Reduce ~200-300 MB
```

**Mejoras adicionales para next.config.js:**

```javascript
// apps/web/next.config.js
module.exports = {
  // Optimizaci√≥n de build
  swcMinify: true,

  // Reducir tama√±o de bundle
  compiler: {
    removeConsole: process.env.NODE_ENV === 'production' ? {
      exclude: ['error', 'warn'],
    } : false,
  },

  // Standalone output (ya implementado)
  output: 'standalone',

  // Optimizar im√°genes
  images: {
    formats: ['image/avif', 'image/webp'],
    minimumCacheTTL: 60,
  },
}
```

#### B. Optimizar Imagen API (De 380MB ‚Üí ~250MB)

```dockerfile
# apps/api/Dockerfile - Optimizaciones

# =========================================
# OPTIMIZACI√ìN 1: Multi-stage m√°s agresivo
# =========================================
FROM python:3.11-alpine AS base  # Alpine en vez de slim
# Alpine: ~50 MB vs Slim: ~130 MB

# Instalar dependencias de compilaci√≥n solo en stage temporal
FROM base AS builder
RUN apk add --no-cache gcc musl-dev libffi-dev

COPY requirements.txt .
RUN pip wheel --no-cache-dir --wheel-dir /wheels -r requirements.txt

# =========================================
# OPTIMIZACI√ìN 2: Stage final minimalista
# =========================================
FROM base AS production

# Solo copiar wheels compilados
COPY --from=builder /wheels /wheels
RUN pip install --no-cache-dir /wheels/* && rm -rf /wheels

# El resto igual...
# Resultado: Reduce ~100-130 MB
```

**Optimizar requirements.txt:**
```bash
# Usar pip-tools para generar requirements.txt optimizado
pip install pip-tools

# Crear requirements.in con solo dependencias directas
cat > apps/api/requirements.in << EOF
fastapi
uvicorn[standard]
motor
beanie
redis
pydantic
python-jose[cryptography]
passlib[argon2]
structlog
EOF

# Generar requirements.txt con versiones bloqueadas
pip-compile requirements.in

# Resultado: Solo dependencias necesarias, sin duplicados
```

### 3. Configurar L√≠mites de Recursos en Docker Compose

**Problema:** Sin l√≠mites, contenedores pueden consumir toda la RAM disponible.

**Soluci√≥n:** Agregar l√≠mites en `docker-compose.yml`

```yaml
# infra/docker-compose.yml

services:
  api:
    deploy:
      resources:
        limits:
          cpus: '1.0'      # M√°ximo 1 CPU core
          memory: 512M     # M√°ximo 512 MB RAM
        reservations:
          cpus: '0.25'     # M√≠nimo 25% de 1 core
          memory: 128M     # M√≠nimo 128 MB RAM

  web:
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G       # Next.js necesita m√°s para builds
        reservations:
          cpus: '0.25'
          memory: 256M

  mongodb:
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M     # MongoDB puede usar mucho si no se limita
        reservations:
          cpus: '0.25'
          memory: 256M
    # Configurar WiredTiger cache
    command: >
      --wiredTigerCacheSizeGB 0.25  # Limitar cache a 256 MB

  redis:
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 128M     # Redis es muy eficiente
        reservations:
          cpus: '0.1'
          memory: 32M
    # Limitar memoria de Redis
    command: >
      redis-server
      --maxmemory 100mb
      --maxmemory-policy allkeys-lru
```

**Beneficios:**
- Previene memory leaks que consuman todo el sistema
- Mejora estabilidad en producci√≥n
- Permite correr m√°s servicios en el mismo hardware
- Facilita debugging de problemas de memoria

### 4. Optimizar MongoDB

#### A. Configuraci√≥n de WiredTiger

```yaml
# docker-compose.yml
mongodb:
  command: >
    mongod
    --wiredTigerCacheSizeGB 0.25
    --wiredTigerCheckpointDelaySecs 60
```

#### B. √çndices Eficientes

```python
# apps/api/src/models/user.py
from beanie import Indexed

class User(Document):
    username: Indexed(str, unique=True)  # √çndice para b√∫squedas r√°pidas
    email: Indexed(str, unique=True)
    created_at: Indexed(datetime)  # Para queries con ORDER BY

    class Settings:
        # Optimizaci√≥n de cache
        use_cache = True
        cache_expiration_time = 300  # 5 minutos
```

#### C. Proyecciones en Queries

```python
# Antes (trae todos los campos)
users = await User.find().to_list()

# Despu√©s (solo campos necesarios)
users = await User.find(
    projection_model=UserListItem  # Solo id, username, email
).to_list()

# Reduce transferencia de datos y memoria
```

### 5. Optimizar Redis

#### A. Configuraci√≥n de Memoria

```bash
# redis.conf o command en docker-compose
maxmemory 100mb
maxmemory-policy allkeys-lru  # Eliminar keys menos usadas

# Desactivar persistencia si no es cr√≠tico (gana velocidad)
save ""
appendonly no
```

#### B. Expiraci√≥n de Keys

```python
# apps/api/src/services/cache_service.py

async def cache_with_ttl(key: str, data: dict, ttl: int = 300):
    """Cache con expiraci√≥n autom√°tica"""
    await redis.setex(
        key,
        ttl,  # 5 minutos por defecto
        json.dumps(data)
    )

# Evita que el cache crezca indefinidamente
```

### 6. Optimizaci√≥n de Next.js

#### A. Configurar SWC Minifier

```javascript
// next.config.js
module.exports = {
  swcMinify: true,  // ~7x m√°s r√°pido que Terser

  // Reducir bundle size
  modularizeImports: {
    'lodash': {
      transform: 'lodash/{{member}}',
    },
  },
}
```

#### B. Lazy Loading de Componentes

```typescript
// Antes
import HeavyComponent from './HeavyComponent'

// Despu√©s
import dynamic from 'next/dynamic'
const HeavyComponent = dynamic(() => import('./HeavyComponent'), {
  loading: () => <Spinner />,
  ssr: false,  // Solo en client-side si es pesado
})

// Reduce initial bundle en ~100-200 KB por componente pesado
```

#### C. Optimizar Fuentes

```typescript
// app/layout.tsx
import { Inter } from 'next/font/google'

const inter = Inter({
  subsets: ['latin'],
  display: 'swap',  // Mejora performance
  preload: true,
})
```

### 7. Optimizaci√≥n de FastAPI

#### A. Workers de Uvicorn Din√°micos

```python
# apps/api/src/main.py
import multiprocessing

def get_workers():
    """Calcula workers √≥ptimos basado en CPU"""
    cpus = multiprocessing.cpu_count()
    # F√≥rmula recomendada: (2 x CPU) + 1
    return min((2 * cpus) + 1, 4)  # Max 4 en desarrollo

# En Dockerfile CMD
CMD ["python", "-m", "uvicorn", "src.main:app",
     "--host", "0.0.0.0", "--port", "8001",
     "--workers", "2"]  # Configurar seg√∫n servidor
```

#### B. Pooling de Conexiones

```python
# apps/api/src/core/database.py
from motor.motor_asyncio import AsyncIOMotorClient

client = AsyncIOMotorClient(
    MONGODB_URL,
    maxPoolSize=50,      # M√°ximo conexiones
    minPoolSize=10,      # M√≠nimo conexiones (mantiene pool caliente)
    maxIdleTimeMS=30000, # Cierra idle despu√©s de 30s
)
```

#### C. Redis Connection Pooling

```python
# apps/api/src/core/cache.py
import aioredis

redis_pool = aioredis.ConnectionPool(
    max_connections=20,
    decode_responses=True,
)
redis = aioredis.Redis(connection_pool=redis_pool)
```

### 8. Monitoreo de Recursos

#### A. Script de Monitoreo

```bash
#!/bin/bash
# scripts/monitor-resources.sh

echo "=== Docker Resources Monitor ==="
echo ""
echo "Container Stats:"
docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.MemPerc}}"
echo ""
echo "Disk Usage:"
docker system df
echo ""
echo "System Memory:"
free -h
echo ""
echo "Top Memory Consumers:"
docker stats --no-stream --format "table {{.Container}}\t{{.MemUsage}}" | sort -k2 -h -r | head -5
```

#### B. Prometheus + Grafana (Opcional)

```yaml
# docker-compose.monitoring.yml
services:
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana:latest
    volumes:
      - grafana_data:/var/lib/grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin

volumes:
  prometheus_data:
  grafana_data:
```

## üìà Resultados Esperados

### Antes de Optimizaciones
```
Disco Docker:      59 GB (55 GB reclaimable)
RAM Contenedores:  628 MB (sin l√≠mites)
Imagen Web:        1.33 GB
Imagen API:        380 MB
Build Time Web:    ~2-3 minutos
```

### Despu√©s de Optimizaciones
```
Disco Docker:      ~8-10 GB (limpieza regular)
RAM Contenedores:  ~600 MB (con l√≠mites configurados)
Imagen Web:        ~400-500 MB (-60%)
Imagen API:        ~250 MB (-35%)
Build Time Web:    ~1-1.5 minutos (-40%)
```

**Ahorro Total de Disco:** ~49 GB (83%)
**Reducci√≥n de Im√°genes:** ~60% m√°s peque√±as
**Mejora de Estabilidad:** L√≠mites previenen OOM kills

## üéØ Plan de Implementaci√≥n Recomendado

### Fase 1: Limpieza Inmediata (5 minutos)
```bash
make clean-docker  # O ejecutar script de limpieza
```
**Impacto:** Libera ~28 GB inmediatamente

### Fase 2: Configurar L√≠mites (10 minutos)
1. Agregar l√≠mites de recursos a `docker-compose.yml`
2. Reiniciar servicios: `make restart`

**Impacto:** Previene problemas futuros de memoria

### Fase 3: Optimizar Dockerfiles (30 minutos)
1. Implementar multi-stage m√°s agresivos
2. Usar Alpine en vez de Slim donde sea posible
3. Rebuild im√°genes: `make build`

**Impacto:** Reduce ~60% tama√±o de im√°genes

### Fase 4: Optimizaciones de Aplicaci√≥n (1-2 horas)
1. Configurar MongoDB WiredTiger
2. Implementar lazy loading en Next.js
3. Configurar workers de Uvicorn
4. Optimizar queries con proyecciones

**Impacto:** Mejora performance general ~30-40%

### Fase 5: Monitoreo Continuo (Setup √∫nico)
1. Configurar script de limpieza autom√°tica
2. Agregar cron job semanal
3. Opcional: Setup Prometheus + Grafana

**Impacto:** Mantiene sistema optimizado a largo plazo

## üí° Tips Adicionales

### Para Desarrollo
- Usar `docker-compose.dev.yml` con vol√∫menes para hot reload
- No configurar l√≠mites muy estrictos (dificulta debugging)
- Mantener build cache para builds r√°pidos

### Para Producci√≥n
- Usar `docker-compose.yml` con l√≠mites configurados
- Implementar limpieza autom√°tica cada semana
- Monitorear m√©tricas con Prometheus
- Considerar Docker Swarm o Kubernetes para escalado

### Comandos √ötiles
```bash
# Ver uso detallado de vol√∫menes
docker system df -v | grep volume

# Encontrar im√°genes m√°s grandes
docker images --format "{{.Repository}}:{{.Tag}} {{.Size}}" | sort -k2 -h -r | head -10

# Monitoreo en tiempo real
watch -n 2 'docker stats --no-stream'

# Espacio usado por cada contenedor
docker ps -q | xargs docker inspect --format='{{.Name}}: {{.SizeRw}}' | sort -k2 -h -r
```
